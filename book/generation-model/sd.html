
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>7. Stable Diffusion Model &#8212; Image generation learning book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'book/generation-model/sd';</script>
    <link rel="canonical" href="https://anyiyou11.github.io/Image-generation-book/book/generation-model/sd.html" />
    <link rel="icon" href="../../_static/fav.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="8. Autoencoder" href="autoencoder.html" />
    <link rel="prev" title="5. Diffusion Model" href="diffusion-model.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Image generation learning book - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Image generation learning book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">PREREQUISITES</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../pre/python-programming-introduction.html">1. Python programming introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pre/python-programming-basics.html">2. Python programming basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pre/python-programming-advanced.html">3. Python programming advanced</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">IMAGE GENERATION MODEL</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="gan.html">4. Generative adversarial networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="diffusion-model.html">5. Diffusion Model</a></li>

<li class="toctree-l1 current active"><a class="current reference internal" href="#">7. Stable Diffusion Model</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="autoencoder.html">8. Autoencoder</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="vae.html">8.7. Variational Autoencoder</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ASSIGNMENTS</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../assignments/python-programming-introduction.html">9. Python programming introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/python-programming-basics.html">10. Python programming basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/python-programming-advanced.html">11. Python programming advanced</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/art-by-gan.html">12. Art by gan</a></li>

<li class="toctree-l1"><a class="reference internal" href="../assignments/denoising-difussion-model.html">14. Denoising Diffusion Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/base-denoising-autoencoder-dimension-reduction.html">15. Base/Denoising Autoencoder &amp; Dimension Reduction</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/anyiyou11/Image-generation-book/master?urlpath=tree/book/generation-model/sd.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/anyiyou11/Image-generation-book/blob/master/book/generation-model/sd.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/anyiyou11/Image-generation-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/anyiyou11/Image-generation-book/edit/main/book/generation-model/sd.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/anyiyou11/Image-generation-book/issues/new?title=Issue%20on%20page%20%2Fbook/generation-model/sd.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/book/generation-model/sd.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Stable Diffusion Model</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">7.1. Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#components">7.2. Components</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diffusion-explainer">7.3. Diffusion Explainer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-representation-generation">7.4. Text Representation Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-representation-refining">7.5. Image Representation Refining</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-upscaling">7.6. Image Upscaling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-prompt-keywords-affect-image-generation">7.7. How do prompt keywords affect image generation?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stable-diffusion-demo">7.8. Stable Diffusion Demo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#your-turn">7.9. Your turn! 🚀</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#acknowledgments">7.10. Acknowledgments</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install the necessary dependencies</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="o">!{</span>sys.executable<span class="o">}</span><span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--quiet<span class="w"> </span>pandas<span class="w"> </span>scikit-learn<span class="w"> </span>numpy<span class="w"> </span>matplotlib<span class="w"> </span>jupyterlab_myst<span class="w"> </span>ipython<span class="w"> </span>tensorflow_addons<span class="w"> </span>opencv-python<span class="w"> </span>requests
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="stable-diffusion-model">
<h1><span class="section-number">7. </span>Stable Diffusion Model<a class="headerlink" href="#stable-diffusion-model" title="Link to this heading">#</a></h1>
<section id="overview">
<h2><span class="section-number">7.1. </span>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h2>
<p>Stable Diffusion is the most advanced model in the Diffusion model family. It employs a more stable, controllable, and efficient approach to generating high-quality images. There have been significant advancements in the quality, speed, and cost of image generation, allowing this model to generate images directly on consumer-grade GPUs, reaching at least 512<em>512 pixel resolution. The latest XL version can generate controllable images at the level of 1024</em>1024 pixels, with a 30x improvement in generation efficiency compared to previous Diffusion models. Currently, Stable Diffusion’s applications are not limited to image generation but are also widely used in areas such as natural language processing, audio, and video generation.</p>
<p>Stable Diffusion can be applied in many fields. Below, I will guide you through its application in the field of text-to-image translation.</p>
<div style="text-align:center;">
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/diffusion-model/sd/text2image.png" width="60%" height="60%" class="bg-white mb-1">
</div>
<p>You can learn in detail how the Stable Diffusion model generates images through this <a class="reference external" href="https://www.youtube.com/watch?v=MXmacOUJUaw&amp;amp;t=2s">video</a>.</p>
</section>
<section id="components">
<h2><span class="section-number">7.2. </span>Components<a class="headerlink" href="#components" title="Link to this heading">#</a></h2>
<p>Stable Diffusion itself is not a single model but a system architecture composed of multiple modules and models. It consists of three core components, each of which is a neural network system, also known as the three fundamental models:</p>
<p><strong>ClipText</strong> for text encoding.
Input: text(prompt).
Output: 77 token embeddings vectors, each in 768 dimensions.</p>
<p><strong>UNet + Scheduler</strong> to gradually process/diffuse information in the information (latent) space.
Input: text embeddings and a starting multi-dimensional array (structured lists of numbers, also called a tensor) made up of noise.
Output: A processed information array</p>
<p><strong>Autoencoder Decoder</strong> that paints the final image using the processed information array.
Input: The processed information array (dimensions: (4,64,64))
Output: The resulting image (dimensions: (3, 512, 512) which are (red/green/blue, width, height))</p>
</section>
<section id="diffusion-explainer">
<h2><span class="section-number">7.3. </span>Diffusion Explainer<a class="headerlink" href="#diffusion-explainer" title="Link to this heading">#</a></h2>
<p>Through this project, let’s learn how Stable Diffusion transforms your text prompt into image!</p>
<div style="text-align:center;">
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/diffusion-model/sd/sd-explainer.png" width="60%" height="60%" class="bg-white mb-1">
</div>
<p><a href="https://static-1300131294.cos.ap-shanghai.myqcloud.com/html/diffusion-model/diffusion-explainer/test.html" target="_blank">Diffusion Explainer</a></p>
</section>
<section id="text-representation-generation">
<h2><span class="section-number">7.4. </span>Text Representation Generation<a class="headerlink" href="#text-representation-generation" title="Link to this heading">#</a></h2>
<p>Clicking Text Representation Generation shows how a text prompt is converted into a text representation, a vector that summarizes the prompt. It consists of two steps: tokenizing and text encoding.</p>
<div style="text-align:center;">
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/diffusion-model/sd/gif/trg.gif" width="60%" height="60%" class="bg-white mb-1">
</div>
<ol class="arabic simple">
<li><p>Tokenizing
Tokenizing is a common way to handle text data to change the text into numbers and process them with neural networks.</p></li>
</ol>
<p>Stable Diffusion tokenizes a text prompt into a sequence of tokens. For example, it splits the text prompt a cute and adorable bunny into the tokens <strong>a</strong>, <strong>cute</strong>, <strong>and</strong>, <strong>adorable</strong>, and <strong>bunny</strong>. Also, to mark the beginning and end of the prompt, Stable Diffusion adds <strong>start</strong> and <strong>end</strong> tokens at the beginning and the end of the tokens. The resulting token sequence for the above example would be <strong>start</strong>, <strong>a</strong>, <strong>cute</strong>, <strong>and</strong>, <strong>adorable</strong>, <strong>bunny</strong>, and <strong>end</strong>.
For easier computation, Stable Diffusion keeps the token sequences of any text prompts to have the same length of 77 by padding or truncating. If the input prompt has fewer than 77 tokens, <strong>end</strong> tokens are added to the end of the sequence until it reaches 77 tokens. If the input prompt has more than 77 tokens, the first 77 tokens are retained and the rest are truncated. The length of 77 was set to balance performance and computational efficiency.</p>
<ol class="arabic simple" start="2">
<li><p>Text encoding
Stable Diffusion converts the token sequence into a text representation. To use the text representation for guiding image generation, Stable Diffusion ensures that the text representation contains the information related to the image depicted in the prompt. This is done by using a special neural network called CLIP.</p></li>
</ol>
<p>CLIP, which consists of an image encoder and a text encoder, is trained to encode an image and its text description into vectors that are similar to each other. Therefore, the text representation for a prompt computed by CLIP’s text encoder is likely to contain information about the images described in the prompt. You can display the visual explanations by clicking the Text Encoder above.</p>
</section>
<section id="image-representation-refining">
<h2><span class="section-number">7.5. </span>Image Representation Refining<a class="headerlink" href="#image-representation-refining" title="Link to this heading">#</a></h2>
<p>Stable Diffusion generates image representation, a vector that numerically summarizes a high-resolution image depicted in the text prompt. This is done by refining a randomly initialized noise over multiple timesteps to gradually improve the image quality and adherence to the prompt. You can change the initial random noise by adjusting the seed in Diffusion Explainer. Click Image Representation Refiner to visualize each refinement step, which involves noise prediction and removal.</p>
<div style="text-align:center;">
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/diffusion-model/sd/gif/irr.gif" width="60%" height="60%" class="bg-white mb-1">
</div>
<ol class="arabic simple">
<li><p>Noise Prediction
At each timestep, a neural network called UNet predicts noise in the image representation of the current timestep. UNet takes three inputs:</p></li>
</ol>
<p><strong>Image representation</strong> of the current timestep
<strong>Text representation</strong> of the prompt to guide what noise should be removed from the current image representation to generate an image adhering to the text prompt
<strong>Timestep</strong> to indicate the amount of noise remaining in the current image representation</p>
<p>In other words, UNet predicts a <strong>prompt-conditioned noise</strong> in the current image representation under the guidance of the text prompt’s representation and timestep.</p>
<p>However, even though we condition the noise prediction with the text prompt, the generated image representation usually does not adhere strongly enough to the text prompt. To improve the adherence, Stable Diffusion measures the impact of the prompt by additionally predicting generic noise conditioned on an empty prompt (” “) and subtracting it from the prompt-conditioned noise:</p>
<p><strong>impact of prompt</strong> = <strong>prompt-conditioned noise</strong> - <strong>generic noise</strong></p>
<p>In other words, the generic noise contributes to better image quality, while the impact of the prompt contributes to the adherence to the prompt. The final noise is a weighted sum of them controlled by a value called guidance scale:</p>
<p><strong>generic noise</strong> + <strong>guidance scale</strong> x <strong>impact of prompt</strong></p>
<p>A guidance scale of 0 means no adherence to the text prompt, while a guidance scale of 1 means using the original prompt-conditioned noise. Larger guidance scales result in stronger adherence to the text prompt, while too large values can lower the image quality. Change the guidance scale value in Diffusion Explainer and see how it changes the generated images.</p>
<ol class="arabic simple" start="2">
<li><p>Noise Removal
Stable Diffusion then decides how much of the predicted noise to actually remove from the image, as determined by an algorithm called scheduler. Removing small amounts of noise helps refine the image gradually and produce sharper images.</p></li>
</ol>
<p>The scheduler makes this decision by accounting for the total number of timesteps. The downscaled noise is then subtracted from the image representation of the current timestep to obtain the refined representation, which becomes the image representation of the next timestep:</p>
<p><strong>image representation of timestep t+1</strong> = <strong>image representation of timestep t</strong> - <strong>downscaled noise</strong></p>
</section>
<section id="image-upscaling">
<h2><span class="section-number">7.6. </span>Image Upscaling<a class="headerlink" href="#image-upscaling" title="Link to this heading">#</a></h2>
<div style="text-align:center;">
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/diffusion-model/sd/gif/upscale.gif" width="60%" height="60%" class="bg-white mb-1">
</div>
<p>After all denoising steps have been completed, Stable Diffusion uses a neural network called Decoder to upscale the image representation into a high-resolution image. The refined image representation fully denoised with the guidance of the text representations would result in a high-resolution image strongly adhering to the text prompt.</p>
</section>
<section id="how-do-prompt-keywords-affect-image-generation">
<h2><span class="section-number">7.7. </span>How do prompt keywords affect image generation?<a class="headerlink" href="#how-do-prompt-keywords-affect-image-generation" title="Link to this heading">#</a></h2>
<div style="text-align:center;">
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/diffusion-model/sd/gif/rcv.gif" width="60%" height="60%" class="bg-white mb-1">
</div>
<p>Writing text prompts can be very heuristic and repetitive. For example, starting from the prompt a cute bunny, you should repetitively add and remove keywords such as in the style of cute pixar character, until you reach to the desired image.</p>
<p>Therefore, understanding how prompt keywords affect image generation would be greatly helpful for writing and refining your prompt. Click the keywords highlighted in the text prompt and compare the image generation of the two prompts that differ only in the keywords.</p>
</section>
<section id="stable-diffusion-demo">
<h2><span class="section-number">7.8. </span>Stable Diffusion Demo<a class="headerlink" href="#stable-diffusion-demo" title="Link to this heading">#</a></h2>
<p>Now you can try inputting positive and negative prompts yourself to generate stunning images online.</p>
<div style="text-align:center;">
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/diffusion-model/sd/sd-web.png" width="60%" height="60%" class="bg-white mb-1">
</div>
<p><a class="reference external" href="https://huggingface.co/spaces/stabilityai/stable-diffusion">Stable Diffusion Demo</a></p>
</section>
<section id="your-turn">
<h2><span class="section-number">7.9. </span>Your turn! 🚀<a class="headerlink" href="#your-turn" title="Link to this heading">#</a></h2>
<p>Assignment - <a class="reference internal" href="../assignments/denoising-difussion-model.html"><span class="std std-doc">Denoising difussion model</span></a></p>
</section>
<section id="acknowledgments">
<h2><span class="section-number">7.10. </span>Acknowledgments<a class="headerlink" href="#acknowledgments" title="Link to this heading">#</a></h2>
<p>Thanks to <a class="reference external" href="https://seongmin.xyz/">Seongmin Lee</a> for creating the open-source project <a class="reference external" href="https://github.com/poloclub/diffusion-explainer">diffusion-explainer</a> and <a class="reference external" href="https://github.com/jalammar">Jay Alammer</a> for creating the open-source courses <a class="reference external" href="https://jalammar.github.io/illustrated-stable-diffusion/">The lllustrated Stable Diffusion</a>. They inspire the majority of the content in this chapter.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./book/generation-model"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="diffusion-model.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">5. </span>Diffusion Model</p>
      </div>
    </a>
    <a class="right-next"
       href="autoencoder.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">8. </span>Autoencoder</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">7.1. Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#components">7.2. Components</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diffusion-explainer">7.3. Diffusion Explainer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-representation-generation">7.4. Text Representation Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-representation-refining">7.5. Image Representation Refining</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-upscaling">7.6. Image Upscaling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-prompt-keywords-affect-image-generation">7.7. How do prompt keywords affect image generation?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stable-diffusion-demo">7.8. Stable Diffusion Demo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#your-turn">7.9. Your turn! 🚀</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#acknowledgments">7.10. Acknowledgments</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By anyiyou
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>